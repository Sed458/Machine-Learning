{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment Logistic Regression\n",
    "Breast Cancer Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Important Libraries\n",
    "from sklearn.datasets import load_breast_cancer # taking included data set from Sklearn http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html\n",
    "from sklearn.linear_model import LogisticRegression # importing Sklearn's logistic regression's module\n",
    "from sklearn import preprocessing # preprossing is what we do with the data before we run the learning algorithm\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset\n",
    "cancer = load_breast_cancer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "Scale before splitting the data into train and test- scale the data since we will be using gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(426,)\n"
     ]
    }
   ],
   "source": [
    "x_scale = preprocessing.scale(cancer.data)\n",
    "y = cancer.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scale, y, random_state=0)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# Printing Names of the Features used for prediction.\n",
    "print(cancer.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Logistic Regression Using Gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code that computes sigmoid of z. Remember sigmoid can be scalar or a matrix.\n",
    "def sigmoid(z):\n",
    "    sig = 1/(1 + np.exp(-z))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid of 0 should be equal to half.\n",
    "print(sigmoid(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 31)\n",
      "[[ 1.         -0.64678318 -0.42577149 ... -0.35335182  0.32395133\n",
      "  -0.76893975]\n",
      " [ 1.         -0.82571213  0.13272462 ... -1.43718102  0.63294742\n",
      "  -1.03770647]\n",
      " [ 1.          1.70485436  2.08513394 ...  0.73382724 -0.53185462\n",
      "  -0.97397828]\n",
      " ...\n",
      " [ 1.         -1.33239345 -0.22564372 ... -0.97581512 -0.72275273\n",
      "  -0.14329518]\n",
      " [ 1.         -1.25173342 -0.24891439 ... -1.74506282 -1.60444316\n",
      "  -1.01720262]\n",
      " [ 1.         -0.74334801  1.07984094 ... -0.27523937 -1.2760337\n",
      "   0.1869831 ]]\n"
     ]
    }
   ],
   "source": [
    "# Appending a Column of Ones in x_train.\n",
    "# ones is a vector of shape n,1\n",
    "ones = np.ones((x_train.shape[0],1))\n",
    "# Append a column of ones in the beginning of x_train an save in variable a.\n",
    "a = np.hstack((ones, x_train))\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Parameter Vector w: A vector of shape x_train.shape[1],1\n",
    "w = np.zeros((a.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis Function. Write code that computes hypothesis using a and w.\n",
    "def hypothesis(a , w):\n",
    "    z = a.dot(w)\n",
    "    h = sigmoid(z)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Predicted Values.\n",
    "yhat = hypothesis(a, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood Function.\n",
    "Write the code to calculate the log likelihood as discussed in the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(X_tr , Y_tr , w , n):\n",
    "    \n",
    "    yhat = hypothesis(X_tr, w)\n",
    "    likelihood = (1/n)*np.sum(Y_tr * np.log(yhat) + (1 - Y_tr) * np.log(1 - yhat))\n",
    "    \n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-295.2806989185367\n"
     ]
    }
   ],
   "source": [
    "# Before moving ahead, run this cell.\n",
    "print(likelihood(a,y_train,w,a.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value should be equal to -295.2806989185367. If this matches, your code is likely to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the function that performs Gradient Ascent.\n",
    "def Gradient_Ascent(a, y, learning_rate, num_iters):\n",
    "    n = a.shape[0] # Number of training examples.\n",
    "    \n",
    "    # Initialize w. Zeros vector of shape x_train.shape[1],1\n",
    "    w = np.zeros((a.shape[1], 1))\n",
    "    \n",
    "    # Reshape y to be a rank 2 matrix.\n",
    "    y = y.reshape(y.shape[0],1)\n",
    "    \n",
    "    # Initiating list to store values of likelihood after few iterations.\n",
    "    likelihood_values = []\n",
    "    for i in range(num_iters):\n",
    "        yhat = hypothesis(a, w)\n",
    "        error = np.sum(a*(y - yhat))\n",
    "        gradient = (learning_rate/n)*error\n",
    "        # Updating Parameters\n",
    "        w = w + gradient\n",
    "        if(i%100 ==0):\n",
    "            likelihood_values.append(likelihood(a, y, w, n))\n",
    "        \n",
    "    return w, likelihood_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]\n",
      " [-0.14297774]]\n",
      "[-0.6927273417214055, -0.654145744329276, -0.6215180311241595, -0.5937741112637651, -0.5700105391803475, -0.5494942969227872, -0.5316416683989582, -0.5159904377488457, -0.5021739271487531, -0.48989956203917806, -0.47893209424203753, -0.4690807668953481, -0.4601895700946745, -0.45212984128502826, -0.4447946212660632, -0.4380943206868856, -0.4319533670500041, -0.42630758920180484, -0.4211021603165182, -0.4162899670461754, -0.4118303064407707, -0.4076878369676322, -0.4038317280589109, -0.4002349659471118, -0.39687378343495977, -0.3937271886311491, -0.3907765732414125, -0.38800538521798805, -0.3853988537883509, -0.3829437573588161, -0.3806282267049484, -0.37844157735450373, -0.376374166240426, -0.37441726862629227, -0.37256297204083233, -0.37080408454432934, -0.36913405512019526, -0.3675469043646, -0.3660371639547779, -0.364599823627331, -0.36323028460297774, -0.36192431856278057, -0.3606780314200189, -0.3594878312471392, -0.3583503998130942, -0.35726266726642386, -0.3562217895664741, -0.3552251283215255, -0.3542702327401316, -0.35335482344218877, -0.35247677791039117, -0.3516341173917664, -0.35082499508378734, -0.35004768546077136, -0.3493005746144887, -0.3485821514985667, -0.347890999979787, -0.3472257916110543, -0.3465852790509336, -0.3459682900634444, -0.3453737220394481, -0.34480053698763896, -0.3442477569489761, -0.3437144597935044, -0.34319977536298796, -0.34270288192671866, -0.34222300292133295, -0.34175940394852217, -0.34131139000723193, -0.340878302939334, -0.3404595190698765, -0.3400544470249045, -0.33966252571151095, -0.3392832224462807, -0.33891603121960984, -0.3385604710845828, -0.3382160846601398, -0.33788243673923485, -0.33755911299352515, -0.3372457187669083, -0.33694187795091196, -0.3366472319355573, -0.33636143862988505, -0.33608417154683123, -0.33581511894759847, -0.3355539830410851, -0.3353004792343006, -0.33505433543004204, -0.33481529136840993, -0.33458309800902103, -0.3343575169510314, -0.3341383198883126, -0.33392528809733457, -0.3337182119555025, -0.3335168904878673, -0.33332113094029153, -0.33313074837729856, -0.3329455653029666, -0.332765411303351, -0.3325901227090325]\n"
     ]
    }
   ],
   "source": [
    "# Call Gradient_Ascent method by passing appropriate values of learning rate and num_iterations.\n",
    "learning_rate = 0.00001\n",
    "num_iters = 10000\n",
    "w, likelihood_values = Gradient_Ascent(a, y_train, learning_rate, num_iters)\n",
    "print(w)\n",
    "print(likelihood_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Likelihood v/s Number of Iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to plot Likelihood v/s Number of Iterations.\n",
    "iters = np.array(range(0,num_iters,100))\n",
    "plt.plot(iters,likelihood_values,'.-',color='green')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Likelihood')\n",
    "plt.title(\"Likelihood vs Number of Iterations.\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the likelihood increasing as number of Iterations increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the function to compute predicted values using a and w.\n",
    "def predict(a, w):\n",
    "    yhat = hypothesis(a, w)\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = predict(a, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the comments in the function carefully.\n",
    "def precision_recall(yhat, y , threshold):\n",
    "    # Write code to compute precision and recall\n",
    "    # Before finding precision or recall, you have to convert yhat into a vector of zeros and ones using threshold.\n",
    "    # Values in yhat > threshold should be equal to 1 and others should be 0.\n",
    "    new_yhat = np.where(yhat > threshold, 1, 0)\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(yhat)): \n",
    "        if y[i]==new_yhat[i]==1:\n",
    "           TP += 1\n",
    "        if new_yhat[i]==1 and y[i]!=new_yhat[i]:\n",
    "           FP += 1\n",
    "        if y[i]==new_yhat[i]==0:\n",
    "           TN += 1\n",
    "        if new_yhat[i]==0 and y[i]!=new_yhat[i]:\n",
    "           FN += 1\n",
    "    \n",
    "    print(TP, FP, TN, FN)\n",
    "    \n",
    "    precision = TP/(TP+FP)\n",
    "    \n",
    "    recall = TP/(TP+FN)\n",
    "    \n",
    "    return precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244 19 140 23\n",
      "0.9277566539923955\n",
      "0.9138576779026217\n"
     ]
    }
   ],
   "source": [
    "precision, recall = precision_recall(yhat, y_train, 0.45)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9207547169811321\n"
     ]
    }
   ],
   "source": [
    "def f_score(precision, recall):\n",
    "    f_score = 2 * (precision * recall)/(precision + recall)\n",
    "    return f_score\n",
    "\n",
    "f_score = f_score(precision, recall)\n",
    "\n",
    "print(f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Model using Sk Learn Library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object of logistic regression model. Pass a large value of C as C = 1/lambda.\n",
    "# So, lambda will become nearly 0.\n",
    "logreg = LogisticRegression(C = 10**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000000000, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the training set. # Write code to fit the model on the training set.\n",
    "# Don't use matrix a. Instead, use x_train.\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1\n",
      " 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0]\n",
      "Accuracy on training data = 0.944056\n"
     ]
    }
   ],
   "source": [
    "# Find the predicted values on training set using logreg.predict\n",
    "# Here, it will return a vector of zeros and ones.\n",
    "yhat = logreg.predict(x_test)\n",
    "# Find the accuracy achieved on training set.\n",
    "acc = logreg.score(x_test, y_test)\n",
    "print(\"Accuracy on training data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 18.51105596  -2.64289962   3.98258584  10.36910065   4.73444148\n",
      "   71.40438387 -37.5635375  -44.98603064 -12.1365401  -19.31716072\n",
      "  -31.56633159  11.53958494   3.63580211 -37.63253338   7.25079893\n",
      "   11.37321482  22.31773462 -40.20809173  -3.55543008  68.18028138\n",
      "  -30.70306856 -23.69679679 -29.02088289 -30.51973279  -4.15230281\n",
      "    5.85554849 -32.86592453  14.4030128    3.00803901 -44.98205143]]\n",
      "[-13.19287194]\n"
     ]
    }
   ],
   "source": [
    "# Printing the parameters.\n",
    "# Retrieving the parameters computed by logreg.\n",
    "w = logreg.coef_\n",
    "intercept = logreg.intercept_\n",
    "\n",
    "print(w)\n",
    "print(intercept)\n",
    "# You can compare the parameters computed by logreg model and gradient ascent. They should be nearly same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9659090909090909\n",
      "0.9444444444444444\n",
      "0.9550561797752809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support nethod of sklearn.\n",
    "prec , recal , fscore,_ = score(y_test,yhat,average='binary') \n",
    "\n",
    "print(prec)\n",
    "print(recal)\n",
    "print(fscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare the values of precision, recall and fscore using the methods you wrote and using sklearn method.\n",
    "To match the values of precision, recall and fscore using both methods, you will have to try different values of threshold in your method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient: \n",
      "[-0.02516809 -0.02133788 -0.02484815 -0.0201779  -0.01256714 -0.01449245\n",
      " -0.01956382 -0.02695935 -0.01169921  0.01046128 -0.01542431  0.00024279\n",
      " -0.0123276  -0.00774968  0.00643283  0.00385968  0.00524895 -0.00870188\n",
      "  0.00246322  0.00990315 -0.02906634 -0.02542529 -0.02781558 -0.02203831\n",
      " -0.02160774 -0.02143947 -0.02512611 -0.03268383 -0.0227816  -0.01200829]\n",
      "0.6274104675269311\n"
     ]
    }
   ],
   "source": [
    "#ridge regression\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "alphas = 10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "ridgecv = RidgeCV(alphas = alphas, cv=5)\n",
    "ridgecv.fit(x_train, y_train)\n",
    "\n",
    "ridge = Ridge(alpha = ridgecv.alpha_, normalize = True)\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "print('The coefficient: ')\n",
    "print(ridge.coef_)\n",
    "\n",
    "print(ridge.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46  7]\n",
      " [ 0 90]]\n",
      "0.9278350515463918\n",
      "1.0\n",
      "0.9625668449197862\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "yhat = ridge.predict(x_test)\n",
    "new_yhat = np.where(yhat > 0.55, 1, 0)\n",
    "\n",
    "cm = confusion_matrix(y_test, new_yhat)\n",
    "print(cm)\n",
    "\n",
    "prec , recal , fscore,_ = score(y_test,new_yhat,average='binary') \n",
    "\n",
    "print(prec)\n",
    "print(recal)\n",
    "print(fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
